{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Using IBM Cloud SQL Query to ETL Weather Data", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<div class=\"pull-left\"><left><img style=\"float: right;\" src=\"http://developer.ibm.com/clouddataservices/wp-content/uploads/sites/85/2018/01/ibm-cloud-object-storage-logo-small.png\" width=\"100\" margin=50></left></div>\n<div style=\"text-align:center\">\nIBM Cloud SQL Query is IBM's serverless SQL service on data in Cloud Object Storage. It allows to run ANSI SQL on Parquet, CSV, JSON, ORC and AVRO data sets. You can use it to run your analytic queries, and you can use it to conduct complex transformations and write the result in any desired data format, partitioning and layout. SQL Query is based on Apache Spark SQL as the query engine in the background. This means you do not have to provision any Apache Spark instance or service. A simple Python client (like the IBM Watson Studio Notebook) is sufficient.<br><br></div>\nThis notebook is meant to be a generic starter to use the SQL Query API in order to run SQL statements in a programmatic way. It uses the <a href=\"https://github.com/IBM-Cloud/sql-query-clients/tree/master/Python\" target=\"_blank\" rel=\"noopener noreferrer\">ibmcloudsql</a> Python library for this purpose. The notebook also demonstrates how you can combine SQL Query with visualization libraries such as PixieDust. The notebook has been verified to work with Python 3.5. As mentioned above it does not require a Spark service bound to the notebook.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Table of contents\n1. [Setup libraries](#setup)<br>\n2. [Configure SQL Query](#configure)<br>\n    2.1 [Using the project bucket](#projectbucket)<br>\n    2.2 [Setting SQL Query parameters](#parameters)<br>\n3. [Your SQL](#sql)<br>\n4. [Running Your SQL Statement](#run)<br>", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### <a id=\"setup\"></a> 1. Setup libraries", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Run the following cell at least once in your notebook environment in order to install required packages, such as the SQL Query client library:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "!pip install --user ibmcloudsql", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Requirement already satisfied: ibmcloudsql in /home/dsxuser/.local/lib/python3.5/site-packages (0.2.23)\nRequirement already satisfied: simplejson in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibmcloudsql) (3.11.1)\nRequirement already satisfied: botocore in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibmcloudsql) (1.7.20)\nRequirement already satisfied: pyarrow in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibmcloudsql) (0.9.0)\nRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibmcloudsql) (2.0.1)\nRequirement already satisfied: tornado<=4.5.2 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibmcloudsql) (4.5.2)\nRequirement already satisfied: numpy in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibmcloudsql) (1.13.3)\nRequirement already satisfied: pandas in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibmcloudsql) (0.21.0)\nRequirement already satisfied: urllib3 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibmcloudsql) (1.22)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from botocore->ibmcloudsql) (0.9.3)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from botocore->ibmcloudsql) (2.6.1)\nRequirement already satisfied: docutils>=0.10 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from botocore->ibmcloudsql) (0.14)\nRequirement already satisfied: six>=1.0.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pyarrow->ibmcloudsql) (1.11.0)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.*,>=2.0.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk->ibmcloudsql) (2.0.1)\nRequirement already satisfied: ibm-cos-sdk-core==2.*,>=2.0.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk->ibmcloudsql) (2.0.1)\nRequirement already satisfied: pytz>=2011k in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pandas->ibmcloudsql) (2018.3)\n\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n"
                }
            ], 
            "execution_count": 1
        }, 
        {
            "source": "import ibmcloudsql\nimport pandas as pd", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 2
        }, 
        {
            "source": "### <a id=\"configure\"></a> 2. Configure SQL Query\n1. You need an **API key** for an IBM cloud identity that has access to your Cloud Object Storage bucket for writing SQL results and to your SQL Query instance. To create API keys log on to the IBM Cloud console and go to <a href=\"https://console.bluemix.net/iam/#/apikeys\" target=\"_blank\">Manage->Security->Platform API Keys</a>, click the `Create` button, give the key a custom name and click `Create`. In the next dialog click `Show` and copy the key to your clipboard and paste it below in this notebook.\n2. You need the **instance CRN** for the SQL Query instance. You can find it in the <a href=\"https://console.bluemix.net/dashboard/apps\" target=\"_blank\">IBM Cloud console dashboard</a>. Make sure you have `All Resources` selected as resource group. In the section `Services` you can see your instances of SQL Query and Cloud Object Storage. Select the instance of SQL Query that you want to use. In the SQL Query dashboard page that opens up you find a section titled **REST API** with a button labelled **Instance CRN**. Click the button to copy the CRN into your clipboard and paste it here into the notebook. If you don't have an SQL Query instance created yet, <a href=\"https://console.bluemix.net/catalog/services/sql-query\" target=\"_blank\">create one</a> first.\n3. You need to specify the location on Cloud Object Storage where your **query results** should be written. This comprises three parts of information that you can find in the Cloud Object Storage UI for your instance in the IBM Cloud console. You need to provide it as a **URL** using the format `cos://<endpoint>/<bucket>/[<prefix>]`. You have the option to use the cloud object storage **bucket that is associated with your project**. In this case, execute the following section before you proceed.  \n<br/>\nFor more background information, check out the SQL Query <a href=\"https://console.bluemix.net/docs/services/sql-query/getting-started.html#getting-started-tutorial\" target=\"_blank\">documentation</a>.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# @hiddencell \n# see e.g. https://console.bluemix.net/docs/tutorials/smart-data-lake.html#build-a-data-lake-using-object-storage for similar steps\n\n# API Key\napikey = '<apikey>'\n\n# SQL Query CRN\ninstnacecrn = '<crn>'\n\n#COS endpoint\nsql_cos_endpoint = 'cos://eu-de/weather-data-demo'", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 3
        }, 
        {
            "source": "#### <a id=\"projectbucket\"></a> 2.1 Using the project bucket\n**Only** follow the instructions in this section when you want to write your SQL query results to the bucket that has been created for the project for which you have created this notebook. In any other case proceed directly with section **2.2**.\n<br><br>\n__Inserting the project token__:  \nClick the `More` option in the toolbar above (the three stacked dots) and select `Insert project token`.\n * If you haven't created an access token for this project before, you will see a dialog that asks you to create one first. Follow the link to open your project settings, scroll down to `Access tokens` and click `New token`. Give the token a custom name and make sure you select `Editor` as `Access role for project`. After you created your access token you can come back to this notebook, select the empty cell below and again select `Insert project token` from the toolbar at the top.\n[//]: # \n\nLeave that cell content as inserted and run the cell. Then then proceed with the following cell below:", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='<project-id>', project_access_token='<project token>')\npc = project.project_context", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 4
        }, 
        {
            "source": "cos_bucket = project.get_metadata()['entity']['storage']['properties']\ntargeturl=\"cos://\" + cos_bucket['bucket_region'] + \"/\" + cos_bucket['bucket_name'] + \"/\"", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 5
        }, 
        {
            "source": "#### <a id=\"parameters\"></a> 2.2 Setting the SQL Query parameters", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "sqlClient = ibmcloudsql.SQLQuery(apikey, instnacecrn, client_info='SQL Query Starter Notebook')\nsqlClient.logon()\nprint('\\nYour SQL Query web console link:\\n')\nsqlClient.sql_ui_link()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\nYour SQL Query web console link:\n\nhttps://sql.ng.bluemix.net/sqlquery/?instance_crn=crn:v1:bluemix:public:sql-query:us-south:a/e97a8c01ac694e308ef3ad7795e48756:b9c3fd30-b752-4a4d-a7a7-51e2ec0d7c1f::\n"
                }
            ], 
            "execution_count": 6
        }, 
        {
            "source": "### <a id=\"sql\"></a> 3. Your SQL\nTo author your own SQL query, use the interactive SQL Query web console (**link above**) of your SQL Query service instance.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "sql = \"WITH wd AS (SELECT day_ind, CAST(from_unixtime(valid_time_gmt) AS DATE) as obs_date, obs_name, temp \\n\" + \\\n          \"FROM \" + sql_cos_endpoint + \"/* STORED AS JSON o WHERE o.class = 'observation') \\n \" + \\\n          \"SELECT wd.obs_name, wd.obs_date, wd.day_ind, ROUND(MIN(wd.temp),1) AS mintemp, ROUND(AVG(wd.temp),1) AS avgtemp, ROUND(MAX(wd.temp),1) AS maxtemp \\n \" + \\\n          \"FROM wd \\n \" + \\\n          \"GROUP BY wd.obs_name, wd.obs_date, wd.day_ind \\n \" + \\\n          \"ORDER BY wd.obs_name, wd.obs_date, wd.day_ind \\n \" + \\\n          \"INTO {}result/ STORED AS CSV\".format(targeturl)\nprint('\\nYour SQL statement is:\\n')\nprint(sql)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "\nYour SQL statement is:\n\nWITH wd AS (SELECT day_ind, CAST(from_unixtime(valid_time_gmt) AS DATE) as obs_date, obs_name, temp \nFROM cos://eu-de/weather-data-demo/* STORED AS JSON o WHERE o.class = 'observation') \n SELECT wd.obs_name, wd.obs_date, wd.day_ind, ROUND(MIN(wd.temp),1) AS mintemp, ROUND(AVG(wd.temp),1) AS avgtemp, ROUND(MAX(wd.temp),1) AS maxtemp \n FROM wd \n GROUP BY wd.obs_name, wd.obs_date, wd.day_ind \n ORDER BY wd.obs_name, wd.obs_date, wd.day_ind \n INTO cos://eu-geo/weatherdatademo-donotdelete-pr-2qk5tcfdz1qs9t/result/ STORED AS CSV\n"
                }
            ], 
            "execution_count": 7
        }, 
        {
            "source": "### <a id=\"run\"></a> 4. Running Your SQL Statement\nThe following cell submits the above SQL statement and waits for it to finish before printing a sample of the result set.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "result_df = sqlClient.run_sql(sql)\nif isinstance(result_df, str):\n    print(result_df)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "execution_count": 8
        }, 
        {
            "source": "result_df.head(10)", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "               obs_name    obs_date day_ind  mintemp  avgtemp  maxtemp\n0  Hamburg/Finkenwerder  2019-04-28       D        8      8.9       13\n1  Hamburg/Finkenwerder  2019-04-28       N        8      9.0       10\n2  Hamburg/Finkenwerder  2019-04-29       D        8     11.7       17\n3  Hamburg/Finkenwerder  2019-04-29       N        4      8.0       13\n4  Hamburg/Finkenwerder  2019-04-30       D        4     11.9       17\n5  Hamburg/Finkenwerder  2019-04-30       N        4      8.0       11\n6  Hamburg/Finkenwerder  2019-05-01       D        9      9.6       11\n7  Hamburg/Finkenwerder  2019-05-01       N        8      8.6        9\n8  Hamburg/Finkenwerder  2019-05-02       D        8      9.9       13\n9  Hamburg/Finkenwerder  2019-05-02       N        6      7.4        8", 
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>obs_name</th>\n      <th>obs_date</th>\n      <th>day_ind</th>\n      <th>mintemp</th>\n      <th>avgtemp</th>\n      <th>maxtemp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hamburg/Finkenwerder</td>\n      <td>2019-04-28</td>\n      <td>D</td>\n      <td>8</td>\n      <td>8.9</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hamburg/Finkenwerder</td>\n      <td>2019-04-28</td>\n      <td>N</td>\n      <td>8</td>\n      <td>9.0</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hamburg/Finkenwerder</td>\n      <td>2019-04-29</td>\n      <td>D</td>\n      <td>8</td>\n      <td>11.7</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hamburg/Finkenwerder</td>\n      <td>2019-04-29</td>\n      <td>N</td>\n      <td>4</td>\n      <td>8.0</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hamburg/Finkenwerder</td>\n      <td>2019-04-30</td>\n      <td>D</td>\n      <td>4</td>\n      <td>11.9</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Hamburg/Finkenwerder</td>\n      <td>2019-04-30</td>\n      <td>N</td>\n      <td>4</td>\n      <td>8.0</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Hamburg/Finkenwerder</td>\n      <td>2019-05-01</td>\n      <td>D</td>\n      <td>9</td>\n      <td>9.6</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Hamburg/Finkenwerder</td>\n      <td>2019-05-01</td>\n      <td>N</td>\n      <td>8</td>\n      <td>8.6</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Hamburg/Finkenwerder</td>\n      <td>2019-05-02</td>\n      <td>D</td>\n      <td>8</td>\n      <td>9.9</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Hamburg/Finkenwerder</td>\n      <td>2019-05-02</td>\n      <td>N</td>\n      <td>6</td>\n      <td>7.4</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
                    }, 
                    "execution_count": 9, 
                    "metadata": {}
                }
            ], 
            "execution_count": 9
        }, 
        {
            "source": "result_df.count()", 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "execute_result", 
                    "data": {
                        "text/plain": "obs_name    32\nobs_date    32\nday_ind     32\nmintemp     32\navgtemp     32\nmaxtemp     32\ndtype: int64"
                    }, 
                    "execution_count": 10, 
                    "metadata": {}
                }
            ], 
            "execution_count": 10
        }, 
        {
            "source": "### <a id=\"next\"></a> 8. Next steps\nIn this notebook you learned how you can use the `ibmcloudsql` library in a Python notebook to submit SQL queries on data in IBM Cloud Object Storage and how you can interact with the query results. If you want to automate such an SQL query execution as part of your cloud solution, you can use the <a href=\"https://console.bluemix.net/openwhisk/\" target=\"_blank\">IBM Cloud Functions</a> framework. There is a dedicated SQL function available that lets you set up a cloud function to run SQL statements with IBM Cloud SQL Query. You can find the documentation for doing this <a href=\"https://hub.docker.com/r/ibmfunctions/sqlquery/\" target=\"_blank\" rel=\"noopener noreferrer\">here</a>.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "### <a id=\"authors\"></a>Authors\n\n**Torsten Steinbach**, Torsten is the lead architect for IBM Cloud SQL Query. Previously he has worked as IBM architect for a series of data management products and services, including DB2, PureData for Analytics and Db2 on Cloud.\n\nThis version has been edited by **Einar Karlsen**. Commands asking for input and for formatting SQL queries have been removed and a default SQL query has been provided that aggregates weather temperatures from The Weather Company service. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<hr>\nCopyright &copy; IBM Corp. 2019. This notebook and its source code are released under the terms of the MIT License.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n</div>", 
            "cell_type": "markdown", 
            "metadata": {}
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5", 
            "name": "python3", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.5", 
            "name": "python", 
            "pygments_lexer": "ipython3", 
            "file_extension": ".py", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}